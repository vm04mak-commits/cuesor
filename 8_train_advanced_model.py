"""
–°–∫—Ä–∏–ø—Ç 8: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
- Feature Engineering (—Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
- Feature Selection (–æ—Ç–±–æ—Ä –ª—É—á—à–∏—Ö)
- Hyperparameter Tuning (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
- Walk-Forward Backtesting (—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
"""

import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import pickle
import warnings
warnings.filterwarnings('ignore')

from core.database import Database
from core.logger import Logger
from core.config import Config
from predict.feature_engineering import FeatureEngineer
from predict.feature_selection import FeatureSelector
from predict.hyperparameter_tuning import HyperparameterTuner
from predict.walk_forward import WalkForwardAnalyzer


def print_header(text: str):
    """–ö—Ä–∞—Å–∏–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫."""
    print("\n" + "=" * 80)
    print(text)
    print("=" * 80)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print_header("üöÄ –ü–†–û–î–í–ò–ù–£–¢–û–ï –û–ë–£–ß–ï–ù–ò–ï ML –ú–û–î–ï–õ–ï–ô")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    config = Config()
    logger = Logger("AdvancedTraining")
    db_path = config.base_path / "data" / "market_data.db"
    database = Database(db_path, logger)
    
    # –ú–µ–Ω—é
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:")
    print("  1. –ë—ã—Å—Ç—Ä–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (Feature Engineering + Selection)")
    print("  2. –ü–æ–ª–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (+ Hyperparameter Tuning)")
    print("  3. Walk-Forward —Ç–µ—Å—Ç (—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)")
    print("  4. –í—Å—ë —Å—Ä–∞–∑—É (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)")
    
    mode_choice = input("\n–†–µ–∂–∏–º (1-4, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1): ").strip() or "1"
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    use_feature_engineering = mode_choice in ['1', '2', '3', '4']
    use_feature_selection = mode_choice in ['1', '2', '3', '4']
    use_hyperparameter_tuning = mode_choice in ['2', '4']
    use_walk_forward = mode_choice in ['3', '4']
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –º–æ–¥–µ–ª–∏:")
    print("  1. Random Forest (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
    print("  2. Gradient Boosting")
    print("  3. Ridge Regression")
    
    model_choice = input("\n–ú–æ–¥–µ–ª—å (1-3, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1): ").strip() or "1"
    
    model_type_map = {
        '1': 'random_forest',
        '2': 'gradient_boosting',
        '3': 'ridge'
    }
    model_type = model_type_map.get(model_choice, 'random_forest')
    
    print(f"\n‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_type}")
    print(f"‚úÖ Feature Engineering: {'–î–∞' if use_feature_engineering else '–ù–µ—Ç'}")
    print(f"‚úÖ Feature Selection: {'–î–∞' if use_feature_selection else '–ù–µ—Ç'}")
    print(f"‚úÖ Hyperparameter Tuning: {'–î–∞' if use_hyperparameter_tuning else '–ù–µ—Ç'}")
    print(f"‚úÖ Walk-Forward Test: {'–î–∞' if use_walk_forward else '–ù–µ—Ç'}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print_header("üìä –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
    
    tickers = database.get_available_tickers()
    print(f"–î–æ—Å—Ç—É–ø–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤: {len(tickers)}")
    
    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print("\n–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Å–µ–º —Ç–∏–∫–µ—Ä–∞–º...")
    all_data = []
    
    for ticker in tickers[:100]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        try:
            quotes = database.load_quotes(ticker)
            indicators = database.load_indicators(ticker)
            
            if quotes.empty or indicators.empty:
                continue
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º
            quotes = quotes.set_index('date')
            data = quotes.join(indicators, how='inner')
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏–∫–µ—Ä
            data['ticker'] = ticker
            
            # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (—Ü–µ–Ω–∞ —á–µ—Ä–µ–∑ 5 –¥–Ω–µ–π)
            data['target'] = data['close'].shift(-5)
            
            # –£–¥–∞–ª—è–µ–º NaN
            data = data.dropna()
            
            if len(data) > 50:
                all_data.append(data)
        
        except Exception as e:
            logger.warning(f"Error loading {ticker}: {e}")
            continue
    
    if not all_data:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        return
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å—ë
    df = pd.concat(all_data, axis=0)
    print(f"\n‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
    print(f"   –ü–µ—Ä–∏–æ–¥: {df.index.min()} - {df.index.max()}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print_header("üîß –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•")
    
    # –í—ã–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    target_col = 'target'
    exclude_cols = ['target', 'ticker', 'open', 'high', 'low', 'close', 'volume']
    
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    X = df[feature_cols].copy()
    y = df[target_col].copy()
    
    # –û—á–∏—Å—Ç–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    X = X.replace([np.inf, -np.inf], np.nan)
    X = X.fillna(0)
    
    print(f"–ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}")
    
    # Feature Engineering
    if use_feature_engineering:
        print_header("üîß FEATURE ENGINEERING")
        
        engineer = FeatureEngineer(
            create_lags=True,
            create_rolling=True,
            create_technical=True,
            create_interactions=True,
            create_temporal=True,
            lag_periods=[1, 2, 3, 5],
            rolling_windows=[3, 5, 10]
        )
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ –≥—Ä—É–ø–ø–∞–º (–ø–æ —Ç–∏–∫–µ—Ä–∞–º)
        X_engineered_list = []
        y_engineered_list = []
        
        for ticker in df['ticker'].unique():
            mask = df['ticker'] == ticker
            X_ticker = X[mask].copy()
            y_ticker = y[mask].copy()
            
            # –ò–Ω–¥–µ–∫—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å DatetimeIndex
            if not isinstance(X_ticker.index, pd.DatetimeIndex):
                X_ticker.index = pd.to_datetime(X_ticker.index)
            
            X_ticker_eng = engineer.fit_transform(X_ticker, target_col='target')
            
            X_engineered_list.append(X_ticker_eng)
            y_engineered_list.append(y_ticker)
        
        X = pd.concat(X_engineered_list, axis=0)
        y = pd.concat(y_engineered_list, axis=0)
        
        # –£–¥–∞–ª—è–µ–º NaN –∏ infinity
        X = X.replace([np.inf, -np.inf], np.nan)
        mask = ~(X.isna().any(axis=1) | y.isna())
        X = X[mask]
        y = y[mask]
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ outliers
        for col in X.columns:
            if X[col].std() > 0:
                upper = X[col].quantile(0.999)
                lower = X[col].quantile(0.001)
                X[col] = X[col].clip(lower, upper)
        
        print(f"–ü–æ—Å–ª–µ Feature Engineering: {X.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print(f"–ó–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(X)}")
    
    # Feature Selection
    if use_feature_selection:
        print_header("üîç FEATURE SELECTION")
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–±–æ—Ä–∫—É –¥–ª—è Feature Selection (—É—Å–∫–æ—Ä–µ–Ω–∏–µ)
        sample_size = min(10000, len(X))
        sample_idx = np.random.choice(len(X), sample_size, replace=False)
        
        X_sample = X.iloc[sample_idx]
        y_sample = y.iloc[sample_idx]
        
        selector = FeatureSelector(
            methods=['correlation', 'variance', 'importance'],
            n_features_to_select=50,
            correlation_threshold=0.95
        )
        
        selector.fit(X_sample, y_sample)
        
        X = selector.transform(X)
        
        print(f"\n–í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selector.selected_features)}")
        print("\n–¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        print(selector.get_feature_scores(top_n=10))
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    from sklearn.model_selection import train_test_split
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, shuffle=True
    )
    
    print(f"\n–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape}")
    print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape}")
    
    # Hyperparameter Tuning
    if use_hyperparameter_tuning:
        print_header("‚öôÔ∏è  HYPERPARAMETER TUNING")
        
        tuner = HyperparameterTuner(
            model_type=model_type,
            tuning_method='random_search',
            cv_folds=5,
            n_iter=30,
            n_jobs=-1
        )
        
        best_model, best_params = tuner.tune(X_train, y_train)
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ
        metrics = tuner.evaluate(X_test, y_test)
        
        print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        for metric, value in metrics.items():
            print(f"   {metric.upper()}: {value:.4f}")
    
    else:
        # –û–±—É—á–∞–µ–º —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        print_header("üéì –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
        
        from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
        from sklearn.linear_model import Ridge
        
        if model_type == 'random_forest':
            model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        elif model_type == 'gradient_boosting':
            model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        elif model_type == 'ridge':
            model = Ridge(random_state=42)
        
        model.fit(X_train, y_train)
        
        # –û—Ü–µ–Ω–∫–∞
        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
        
        y_pred = model.predict(X_test)
        
        metrics = {
            'r2': r2_score(y_test, y_pred),
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
            'mae': mean_absolute_error(y_test, y_pred),
            'mape': np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100
        }
        
        print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        for metric, value in metrics.items():
            print(f"   {metric.upper()}: {value:.4f}")
        
        best_model = model
        best_params = model.get_params()
    
    # Walk-Forward Backtesting
    if use_walk_forward:
        print_header("üìà WALK-FORWARD BACKTESTING")
        
        # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ —Å DatetimeIndex
        X_wf = X.copy()
        y_wf = y.copy()
        
        if not isinstance(X_wf.index, pd.DatetimeIndex):
            print("‚ö†Ô∏è  –ò–Ω–¥–µ–∫—Å –Ω–µ DatetimeIndex, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º Walk-Forward")
        else:
            # Model factory
            def create_model():
                if model_type == 'random_forest':
                    return RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)
                elif model_type == 'gradient_boosting':
                    return GradientBoostingRegressor(**best_params, random_state=42)
                elif model_type == 'ridge':
                    return Ridge(**best_params, random_state=42)
            
            analyzer = WalkForwardAnalyzer(
                train_size=100,
                test_size=20,
                mode='rolling',
                retrain_frequency=40
            )
            
            wf_results = analyzer.run(X_wf, y_wf, create_model)
            
            print(f"\nüìä Walk-Forward —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            print(f"   –û–∫–æ–Ω: {wf_results['n_windows']}")
            print(f"   –°—Ä–µ–¥–Ω–∏–π R¬≤: {wf_results['mean_r2']:.4f} ¬± {wf_results['std_r2']:.4f}")
            print(f"   –î–∏–∞–ø–∞–∑–æ–Ω R¬≤: [{wf_results['min_r2']:.4f}, {wf_results['max_r2']:.4f}]")
            print(f"   –°—Ä–µ–¥–Ω–∏–π RMSE: {wf_results['mean_rmse']:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print_header("üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    
    models_dir = Path("models/advanced")
    models_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    model_name = f"advanced_{model_type}_{timestamp}"
    model_path = models_dir / f"{model_name}.pkl"
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    model_data = {
        'model': best_model,
        'model_type': model_type,
        'params': best_params,
        'features': X.columns.tolist(),
        'metrics': metrics,
        'feature_engineering': use_feature_engineering,
        'feature_selection': use_feature_selection,
        'hyperparameter_tuning': use_hyperparameter_tuning,
        'timestamp': timestamp
    }
    
    with open(model_path, 'wb') as f:
        pickle.dump(model_data, f)
    
    print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    
    # –ò—Ç–æ–≥–∏
    print_header("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    
    print(f"\n–ú–æ–¥–µ–ª—å: {model_type}")
    print(f"–ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(X.columns)}")
    print(f"R¬≤ Score: {metrics['r2']:.4f}")
    print(f"RMSE: {metrics['rmse']:.4f}")
    print(f"MAE: {metrics['mae']:.4f}")
    
    print(f"\nüí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç—É –º–æ–¥–µ–ª—å –≤:")
    print(f"   - python 4_predict_stocks.py")
    print(f"   - python 7_portfolio_trading.py")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

