"""
Feature Selection –¥–ª—è ML –º–æ–¥–µ–ª–µ–π

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:
- –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—É–¥–∞–ª–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö)
- Feature Importance (–∏–∑ tree-based –º–æ–¥–µ–ª–µ–π)
- –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (RFE)
- Statistical tests (ANOVA, mutual information)
- Variance threshold (—É–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö)
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Tuple, Optional
from sklearn.feature_selection import (
    SelectKBest, f_regression, mutual_info_regression,
    RFE, VarianceThreshold
)
from sklearn.ensemble import RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')


class FeatureSelector:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
    
    def __init__(
        self,
        methods: List[str] = None,
        n_features_to_select: Optional[int] = None,
        correlation_threshold: float = 0.95,
        variance_threshold: float = 0.01
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Feature Selector.
        
        Args:
            methods: –ú–µ—Ç–æ–¥—ã –æ—Ç–±–æ—Ä–∞ ['correlation', 'variance', 'statistical', 'importance', 'rfe']
            n_features_to_select: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞ (None = –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            correlation_threshold: –ü–æ—Ä–æ–≥ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            variance_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è
        """
        self.methods = methods or ['correlation', 'variance', 'importance']
        self.n_features_to_select = n_features_to_select
        self.correlation_threshold = correlation_threshold
        self.variance_threshold = variance_threshold
        
        self.selected_features: List[str] = []
        self.feature_scores: Dict[str, float] = {}
        self.removed_features: Dict[str, str] = {}  # feature -> reason
    
    def fit(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        feature_names: Optional[List[str]] = None
    ) -> 'FeatureSelector':
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ª—É—á—à–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.
        
        Args:
            X: –ü—Ä–∏–∑–Ω–∞–∫–∏
            y: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            feature_names: –ù–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–µ—Å–ª–∏ X –Ω–µ DataFrame)
            
        Returns:
            self
        """
        if not isinstance(X, pd.DataFrame):
            if feature_names is None:
                feature_names = [f"feature_{i}" for i in range(X.shape[1])]
            X = pd.DataFrame(X, columns=feature_names)
        
        print(f"\nüîç Feature Selection:")
        print(f"   –ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
        
        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –æ—Ç–±–æ—Ä–æ–º
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(0)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        for col in X.columns:
            if X[col].abs().max() > 1e15:
                X[col] = X[col].clip(-1e15, 1e15)
        
        print(f"   –î–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã (inf, nan, outliers)")
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å–æ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        selected = X.columns.tolist()
        
        # 1. –£–¥–∞–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π
        if 'variance' in self.methods:
            selected = self._remove_low_variance(X[selected], selected)
        
        # 2. –£–¥–∞–ª—è–µ–º –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
        if 'correlation' in self.methods:
            selected = self._remove_correlated(X[selected], selected)
        
        # 3. Statistical tests (ANOVA, mutual information)
        if 'statistical' in self.methods:
            selected = self._statistical_selection(X[selected], y, selected)
        
        # 4. Feature Importance –∏–∑ Random Forest
        if 'importance' in self.methods:
            selected = self._importance_selection(X[selected], y, selected)
        
        # 5. Recursive Feature Elimination
        if 'rfe' in self.methods:
            selected = self._rfe_selection(X[selected], y, selected)
        
        self.selected_features = selected
        
        print(f"   –í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(self.selected_features)}")
        print(f"   –£–¥–∞–ª–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(self.removed_features)}")
        
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        –ü—Ä–∏–º–µ–Ω–∏—Ç—å –æ—Ç–±–æ—Ä –∫ –¥–∞–Ω–Ω—ã–º.
        
        Args:
            X: –ü—Ä–∏–∑–Ω–∞–∫–∏
            
        Returns:
            DataFrame —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        if not self.selected_features:
            raise ValueError("fit() must be called before transform()")
        
        return X[self.selected_features]
    
    def fit_transform(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        feature_names: Optional[List[str]] = None
    ) -> pd.DataFrame:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –æ—Ç–±–æ—Ä.
        
        Args:
            X: –ü—Ä–∏–∑–Ω–∞–∫–∏
            y: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            feature_names: –ù–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            
        Returns:
            DataFrame —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        self.fit(X, y, feature_names)
        return self.transform(X)
    
    def _remove_low_variance(
        self,
        X: pd.DataFrame,
        features: List[str]
    ) -> List[str]:
        """–£–¥–∞–ª–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π."""
        selector = VarianceThreshold(threshold=self.variance_threshold)
        selector.fit(X)
        
        selected = []
        for i, feature in enumerate(features):
            if selector.get_support()[i]:
                selected.append(feature)
            else:
                self.removed_features[feature] = "low_variance"
        
        return selected
    
    def _remove_correlated(
        self,
        X: pd.DataFrame,
        features: List[str]
    ) -> List[str]:
        """–£–¥–∞–ª–∏—Ç—å –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏."""
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
        corr_matrix = X.corr().abs()
        
        # –í–µ—Ä—Ö–Ω–∏–π —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫
        upper = corr_matrix.where(
            np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
        )
        
        # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π > threshold
        to_drop = [
            column for column in upper.columns
            if any(upper[column] > self.correlation_threshold)
        ]
        
        for feature in to_drop:
            if feature in features:
                self.removed_features[feature] = f"high_correlation(>{self.correlation_threshold})"
        
        selected = [f for f in features if f not in to_drop]
        
        return selected
    
    def _statistical_selection(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        features: List[str]
    ) -> List[str]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä (ANOVA F-test –∏ Mutual Information)."""
        n_features = self.n_features_to_select or max(10, len(features) // 2)
        n_features = min(n_features, len(features))
        
        # F-score
        selector_f = SelectKBest(score_func=f_regression, k=n_features)
        selector_f.fit(X, y)
        
        # Mutual Information
        selector_mi = SelectKBest(score_func=mutual_info_regression, k=n_features)
        selector_mi.fit(X, y)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        scores_f = dict(zip(features, selector_f.scores_))
        scores_mi = dict(zip(features, selector_mi.scores_))
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —É—Å—Ä–µ–¥–Ω—è–µ–º
        max_f = max(scores_f.values())
        max_mi = max(scores_mi.values())
        
        combined_scores = {}
        for feature in features:
            score = (scores_f[feature] / max_f + scores_mi[feature] / max_mi) / 2
            combined_scores[feature] = score
            self.feature_scores[feature] = score
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø N
        sorted_features = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)
        selected = [f for f, _ in sorted_features[:n_features]]
        
        return selected
    
    def _importance_selection(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        features: List[str]
    ) -> List[str]:
        """–û—Ç–±–æ—Ä –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏–∑ Random Forest."""
        n_features = self.n_features_to_select or max(10, len(features) // 2)
        n_features = min(n_features, len(features))
        
        # –û–±—É—á–∞–µ–º Random Forest
        rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        rf.fit(X, y)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å
        importances = dict(zip(features, rf.feature_importances_))
        
        # –û–±–Ω–æ–≤–ª—è–µ–º scores
        for feature, importance in importances.items():
            if feature in self.feature_scores:
                # –£—Å—Ä–µ–¥–Ω—è–µ–º —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–º–∏ scores
                self.feature_scores[feature] = (
                    self.feature_scores[feature] + importance
                ) / 2
            else:
                self.feature_scores[feature] = importance
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø N
        sorted_features = sorted(
            self.feature_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        selected = [f for f, _ in sorted_features[:n_features]]
        
        return selected
    
    def _rfe_selection(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        features: List[str]
    ) -> List[str]:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
        n_features = self.n_features_to_select or max(10, len(features) // 3)
        n_features = min(n_features, len(features))
        
        # RFE —Å Random Forest
        estimator = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
        selector = RFE(estimator, n_features_to_select=n_features, step=1)
        
        selector.fit(X, y)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        selected = [
            features[i] for i in range(len(features))
            if selector.support_[i]
        ]
        
        return selected
    
    def get_feature_scores(self, top_n: int = None) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–∏—Ç—å scores –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        
        Args:
            top_n: –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø N (None = –≤—Å–µ)
            
        Returns:
            DataFrame —Å–æ scores
        """
        df = pd.DataFrame({
            'feature': list(self.feature_scores.keys()),
            'score': list(self.feature_scores.values())
        })
        
        df = df.sort_values('score', ascending=False)
        
        if top_n:
            df = df.head(top_n)
        
        return df
    
    def get_removed_features(self) -> pd.DataFrame:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏."""
        if not self.removed_features:
            return pd.DataFrame(columns=['feature', 'reason'])
        
        df = pd.DataFrame({
            'feature': list(self.removed_features.keys()),
            'reason': list(self.removed_features.values())
        })
        
        return df


def select_best_features(
    X: pd.DataFrame,
    y: pd.Series,
    n_features: Optional[int] = None,
    methods: List[str] = None
) -> Tuple[pd.DataFrame, FeatureSelector]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    
    Args:
        X: –ü—Ä–∏–∑–Ω–∞–∫–∏
        y: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        n_features: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞
        methods: –ú–µ—Ç–æ–¥—ã –æ—Ç–±–æ—Ä–∞
        
    Returns:
        (–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, Selector –æ–±—ä–µ–∫—Ç)
    """
    selector = FeatureSelector(
        methods=methods or ['correlation', 'variance', 'importance'],
        n_features_to_select=n_features
    )
    
    X_selected = selector.fit_transform(X, y)
    
    return X_selected, selector


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print("=" * 80)
    print("üß™ –¢–ï–°–¢ FEATURE SELECTION")
    print("=" * 80)
    
    # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    np.random.seed(42)
    n_samples = 1000
    n_features = 50
    
    X = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f"feature_{i}" for i in range(n_features)]
    )
    
    # –î–µ–ª–∞–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏
    X['feature_1'] = X['feature_0'] * 0.95 + np.random.randn(n_samples) * 0.1
    X['feature_2'] = X['feature_0'] * 0.98 + np.random.randn(n_samples) * 0.05
    
    # –°–æ–∑–¥–∞—ë–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø–µ—Ä–≤—ã—Ö 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
    y = (
        X['feature_0'] * 2 +
        X['feature_3'] * 1.5 +
        X['feature_7'] * 1.2 +
        np.random.randn(n_samples) * 0.5
    )
    
    print(f"\n–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {X.shape}")
    print(f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {y.shape}")
    
    # –û—Ç–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    selector = FeatureSelector(
        methods=['correlation', 'variance', 'statistical', 'importance'],
        n_features_to_select=15
    )
    
    X_selected = selector.fit_transform(X, y)
    
    print(f"\n–í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_selected.shape[1]}")
    
    print("\nüìä –¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ score:")
    print(selector.get_feature_scores(top_n=10))
    
    print("\n‚ùå –£–¥–∞–ª—ë–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
    print(selector.get_removed_features().head())
    
    print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω!")

