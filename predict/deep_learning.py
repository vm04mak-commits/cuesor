"""
Deep Learning Models Module

LSTM/GRU –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤.
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import logging

try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers, models, callbacks
    TENSORFLOW_AVAILABLE = True
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ GPU –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            # –†–∞–∑—Ä–µ—à–∞–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –≤—ã–¥–µ–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"üöÄ GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {len(gpus)} —É—Å—Ç—Ä–æ–π—Å—Ç–≤")
        except RuntimeError as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GPU: {e}")
    else:
        print("üíª GPU –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
        
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("‚ö†Ô∏è  TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install tensorflow>=2.12.0")


class DeepLearningPredictor:
    """
    Deep Learning –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–Ω –∞–∫—Ü–∏–π.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
    - LSTM (Long Short-Term Memory)
    - GRU (Gated Recurrent Unit)
    - 1D CNN
    - Hybrid (CNN + LSTM)
    """
    
    def __init__(
        self,
        model_type: str = 'LSTM',
        sequence_length: int = 30,
        logger: Optional[logging.Logger] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Deep Learning Predictor.
        
        Args:
            model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏ ('LSTM', 'GRU', 'CNN', 'Hybrid')
            sequence_length: –î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–¥–Ω–µ–π)
            logger: –õ–æ–≥–≥–µ—Ä
        """
        if not TENSORFLOW_AVAILABLE:
            raise ImportError("TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install tensorflow>=2.12.0")
        
        self.model_type = model_type
        self.sequence_length = sequence_length
        self.logger = logger
        self.model = None
        self.history = None
        self.scaler_X = None
        self.scaler_y = None
    
    # ========== –°–û–ó–î–ê–ù–ò–ï –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô ==========
    
    def create_sequences(
        self,
        X: np.ndarray,
        y: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è RNN –º–æ–¥–µ–ª–µ–π.
        
        Args:
            X: –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            y: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            
        Returns:
            Tuple[X_sequences, y_sequences]
        """
        X_sequences = []
        y_sequences = []
        
        for i in range(len(X) - self.sequence_length):
            X_sequences.append(X[i:i+self.sequence_length])
            y_sequences.append(y[i+self.sequence_length])
        
        return np.array(X_sequences), np.array(y_sequences)
    
    # ========== –ü–û–°–¢–†–û–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô ==========
    
    def build_lstm_model(
        self,
        input_shape: Tuple,
        units: List[int] = [128, 64],
        dropout: float = 0.2
    ) -> keras.Model:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ LSTM –º–æ–¥–µ–ª–∏.
        
        Args:
            input_shape: –§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞ (sequence_length, n_features)
            units: –°–ø–∏—Å–æ–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Å–ª–æ—è—Ö
            dropout: Dropout rate
            
        Returns:
            Keras –º–æ–¥–µ–ª—å
        """
        model = models.Sequential()
        
        # –ü–µ—Ä–≤—ã–π LSTM —Å–ª–æ–π
        model.add(layers.LSTM(
            units[0],
            return_sequences=len(units) > 1,
            input_shape=input_shape
        ))
        model.add(layers.Dropout(dropout))
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ LSTM —Å–ª–æ–∏
        for i in range(1, len(units)):
            return_seq = i < len(units) - 1
            model.add(layers.LSTM(units[i], return_sequences=return_seq))
            model.add(layers.Dropout(dropout))
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        model.add(layers.Dense(1))
        
        return model
    
    def build_gru_model(
        self,
        input_shape: Tuple,
        units: List[int] = [128, 64],
        dropout: float = 0.2
    ) -> keras.Model:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ GRU –º–æ–¥–µ–ª–∏.
        
        Args:
            input_shape: –§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞
            units: –°–ø–∏—Å–æ–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–µ–π—Ä–æ–Ω–æ–≤
            dropout: Dropout rate
            
        Returns:
            Keras –º–æ–¥–µ–ª—å
        """
        model = models.Sequential()
        
        # –ü–µ—Ä–≤—ã–π GRU —Å–ª–æ–π
        model.add(layers.GRU(
            units[0],
            return_sequences=len(units) > 1,
            input_shape=input_shape
        ))
        model.add(layers.Dropout(dropout))
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ GRU —Å–ª–æ–∏
        for i in range(1, len(units)):
            return_seq = i < len(units) - 1
            model.add(layers.GRU(units[i], return_sequences=return_seq))
            model.add(layers.Dropout(dropout))
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        model.add(layers.Dense(1))
        
        return model
    
    def build_cnn_model(
        self,
        input_shape: Tuple,
        filters: List[int] = [64, 32],
        kernel_size: int = 3,
        dropout: float = 0.2
    ) -> keras.Model:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ 1D CNN –º–æ–¥–µ–ª–∏.
        
        Args:
            input_shape: –§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞
            filters: –°–ø–∏—Å–æ–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤
            kernel_size: –†–∞–∑–º–µ—Ä kernel
            dropout: Dropout rate
            
        Returns:
            Keras –º–æ–¥–µ–ª—å
        """
        model = models.Sequential()
        
        # Conv1D —Å–ª–æ–∏
        for i, f in enumerate(filters):
            if i == 0:
                model.add(layers.Conv1D(f, kernel_size, activation='relu', input_shape=input_shape))
            else:
                model.add(layers.Conv1D(f, kernel_size, activation='relu'))
            model.add(layers.MaxPooling1D(pool_size=2))
            model.add(layers.Dropout(dropout))
        
        # Flatten –∏ Dense
        model.add(layers.Flatten())
        model.add(layers.Dense(64, activation='relu'))
        model.add(layers.Dropout(dropout))
        model.add(layers.Dense(1))
        
        return model
    
    def build_hybrid_model(
        self,
        input_shape: Tuple,
        cnn_filters: List[int] = [64, 32],
        lstm_units: List[int] = [64],
        dropout: float = 0.2
    ) -> keras.Model:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Hybrid –º–æ–¥–µ–ª–∏ (CNN + LSTM).
        
        Args:
            input_shape: –§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞
            cnn_filters: –§–∏–ª—å—Ç—Ä—ã CNN
            lstm_units: –ù–µ–π—Ä–æ–Ω—ã LSTM
            dropout: Dropout rate
            
        Returns:
            Keras –º–æ–¥–µ–ª—å
        """
        model = models.Sequential()
        
        # CNN —Å–ª–æ–∏
        for i, f in enumerate(cnn_filters):
            if i == 0:
                model.add(layers.Conv1D(f, 3, activation='relu', input_shape=input_shape))
            else:
                model.add(layers.Conv1D(f, 3, activation='relu'))
            model.add(layers.MaxPooling1D(pool_size=2))
            model.add(layers.Dropout(dropout))
        
        # LSTM —Å–ª–æ–∏
        for i, units in enumerate(lstm_units):
            return_seq = i < len(lstm_units) - 1
            model.add(layers.LSTM(units, return_sequences=return_seq))
            model.add(layers.Dropout(dropout))
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        model.add(layers.Dense(1))
        
        return model
    
    # ========== –û–ë–£–ß–ï–ù–ò–ï ==========
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: Optional[np.ndarray] = None,
        y_val: Optional[np.ndarray] = None,
        epochs: int = 100,
        batch_size: int = 32,
        learning_rate: float = 0.001,
        early_stopping_patience: int = 10,
        **model_params
    ) -> Dict:
        """
        –û–±—É—á–µ–Ω–∏–µ Deep Learning –º–æ–¥–µ–ª–∏.
        
        Args:
            X_train: –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞ (–ø—Ä–∏–∑–Ω–∞–∫–∏)
            y_train: –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞ (—Ü–µ–ª–µ–≤–∞—è)
            X_val: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ (–ø—Ä–∏–∑–Ω–∞–∫–∏)
            y_val: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ (—Ü–µ–ª–µ–≤–∞—è)
            epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            learning_rate: Learning rate
            early_stopping_patience: –¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è early stopping
            **model_params: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
            
        Returns:
            Dict: –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è –∏ –º–µ—Ç—Ä–∏–∫–∏
        """
        print("\n" + "="*80)
        print(f"ü§ñ –û–ë–£–ß–ï–ù–ò–ï {self.model_type} –ú–û–î–ï–õ–ò")
        print("="*80)
        print()
        
        # –°–æ–∑–¥–∞—ë–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (length={self.sequence_length})...")
        X_train_seq, y_train_seq = self.create_sequences(X_train, y_train)
        
        if X_val is not None and y_val is not None:
            X_val_seq, y_val_seq = self.create_sequences(X_val, y_val)
            validation_data = (X_val_seq, y_val_seq)
        else:
            validation_data = None
        
        print(f"   Train sequences: {X_train_seq.shape}")
        if validation_data:
            print(f"   Val sequences:   {X_val_seq.shape}")
        print()
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        print(f"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ {self.model_type} –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã...")
        input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])
        
        if self.model_type == 'LSTM':
            self.model = self.build_lstm_model(input_shape, **model_params)
        elif self.model_type == 'GRU':
            self.model = self.build_gru_model(input_shape, **model_params)
        elif self.model_type == 'CNN':
            self.model = self.build_cnn_model(input_shape, **model_params)
        elif self.model_type == 'Hybrid':
            self.model = self.build_hybrid_model(input_shape, **model_params)
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")
        
        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è
        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
        self.model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞")
        print()
        print("–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:")
        self.model.summary(print_fn=lambda x: print(f"   {x}"))
        print()
        
        # Callbacks
        callback_list = []
        
        # Early Stopping
        early_stop = callbacks.EarlyStopping(
            monitor='val_loss' if validation_data else 'loss',
            patience=early_stopping_patience,
            restore_best_weights=True,
            verbose=1
        )
        callback_list.append(early_stop)
        
        # Reduce LR on Plateau
        reduce_lr = callbacks.ReduceLROnPlateau(
            monitor='val_loss' if validation_data else 'loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7,
            verbose=1
        )
        callback_list.append(reduce_lr)
        
        # –û–±—É—á–µ–Ω–∏–µ
        print(f"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è ({epochs} —ç–ø–æ—Ö, batch_size={batch_size})...")
        print()
        
        self.history = self.model.fit(
            X_train_seq, y_train_seq,
            validation_data=validation_data,
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callback_list,
            verbose=1
        )
        
        print()
        print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        print()
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        train_loss = self.history.history['loss'][-1]
        train_mae = self.history.history['mae'][-1]
        
        results = {
            'train_loss': train_loss,
            'train_mae': train_mae,
            'epochs_trained': len(self.history.history['loss']),
            'history': self.history.history
        }
        
        if validation_data:
            val_loss = self.history.history['val_loss'][-1]
            val_mae = self.history.history['val_mae'][-1]
            results['val_loss'] = val_loss
            results['val_mae'] = val_mae
        
        # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏
        print("üìä –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
        print(f"   Train Loss: {train_loss:.4f}")
        print(f"   Train MAE:  {train_mae:.4f}")
        if validation_data:
            print(f"   Val Loss:   {val_loss:.4f}")
            print(f"   Val MAE:    {val_mae:.4f}")
        print()
        
        return results
    
    # ========== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï ==========
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            X: –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            
        Returns:
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        """
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ train()")
        
        # –°–æ–∑–¥–∞—ë–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–±–µ–∑ y, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º)
        X_sequences = []
        for i in range(len(X) - self.sequence_length + 1):
            X_sequences.append(X[i:i+self.sequence_length])
        
        X_sequences = np.array(X_sequences)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        predictions = self.model.predict(X_sequences, verbose=0)
        
        return predictions.flatten()
    
    # ========== –°–û–•–†–ê–ù–ï–ù–ò–ï/–ó–ê–ì–†–£–ó–ö–ê ==========
    
    def save_model(self, path: str):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.
        
        Args:
            path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        if self.model is None:
            raise ValueError("–ù–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        
        self.model.save(path)
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {path}")
    
    def load_model(self, path: str):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏.
        
        Args:
            path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        """
        self.model = keras.models.load_model(path)
        print(f"üì¶ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {path}")
    
    # ========== –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ==========
    
    def plot_training_history(self):
        """
        –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è.
        """
        if self.history is None:
            print("–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è")
            return
        
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        # Loss
        axes[0].plot(self.history.history['loss'], label='Train Loss')
        if 'val_loss' in self.history.history:
            axes[0].plot(self.history.history['val_loss'], label='Val Loss')
        axes[0].set_title('Model Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss (MSE)')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # MAE
        axes[1].plot(self.history.history['mae'], label='Train MAE')
        if 'val_mae' in self.history.history:
            axes[1].plot(self.history.history['val_mae'], label='Val MAE')
        axes[1].set_title('Model MAE')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('MAE')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()


class EnsemblePredictor:
    """
    Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π.
    """
    
    def __init__(self, models: List, weights: Optional[List[float]] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ensemble.
        
        Args:
            models: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
            weights: –í–µ—Å–∞ –º–æ–¥–µ–ª–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.models = models
        
        if weights is None:
            self.weights = [1.0 / len(models)] * len(models)
        else:
            if len(weights) != len(models):
                raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Å–æ–≤ –¥–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –º–æ–¥–µ–ª–µ–π")
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
            total = sum(weights)
            self.weights = [w / total for w in weights]
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ.
        
        Args:
            X: –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            
        Returns:
            –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        """
        predictions = []
        
        for model in self.models:
            pred = model.predict(X)
            predictions.append(pred)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
        predictions = np.array(predictions)
        ensemble_pred = np.average(predictions, axis=0, weights=self.weights)
        
        return ensemble_pred
    
    def predict_with_uncertainty(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –æ—Ü–µ–Ω–∫–æ–π –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏.
        
        Args:
            X: –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            
        Returns:
            Tuple[predictions, std]: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
        """
        predictions = []
        
        for model in self.models:
            pred = model.predict(X)
            predictions.append(pred)
        
        predictions = np.array(predictions)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –∏ std
        ensemble_pred = np.average(predictions, axis=0, weights=self.weights)
        ensemble_std = np.std(predictions, axis=0)
        
        return ensemble_pred, ensemble_std






